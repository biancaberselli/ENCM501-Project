{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2d74e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import uuid\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f5454cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = 'data'\n",
    "number_images = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "951d35cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting image 0\n",
      "Collecting image 1\n",
      "Collecting image 2\n",
      "Collecting image 3\n",
      "Collecting image 4\n",
      "Collecting image 5\n",
      "Collecting image 6\n",
      "Collecting image 7\n",
      "Collecting image 8\n",
      "Collecting image 9\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "for imgnum in range(number_images):\n",
    "    print('Collecting image {}'.format(imgnum))\n",
    "    ret, frame = cap.read()\n",
    "    imgname = os.path.join(IMAGES_PATH,f'{str(uuid.uuid1())}.jpg')\n",
    "    cv2.imwrite(imgname, frame)\n",
    "    cv2.imshow('frame', frame)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7d5cb3",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e351aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\berse\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d50ba51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6a8b5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(x): \n",
    "    byte_img = tf.io.read_file(x)\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be0535af",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'data\\\\train\\\\images'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m folder \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, folder, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m      4\u001b[0m         filename \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      5\u001b[0m         existing_filepath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m, filename)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'data\\\\train\\\\images'"
     ]
    }
   ],
   "source": [
    "for folder in ['train','test','val']:\n",
    "    for file in os.listdir(os.path.join('data', folder, 'images')):\n",
    "        \n",
    "        filename = file.split('.')[0]+'.json'\n",
    "        existing_filepath = os.path.join('data','labels', filename)\n",
    "        if os.path.exists(existing_filepath): \n",
    "            new_filepath = os.path.join('data',folder,'labels',filename)\n",
    "            os.replace(existing_filepath, new_filepath) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a89e512",
   "metadata": {},
   "source": [
    "### Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f311331e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as alb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c6b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor = alb.Compose([alb.RandomCrop(width=450, height=450), \n",
    "                         alb.HorizontalFlip(p=0.5), \n",
    "                         alb.RandomBrightnessContrast(p=0.2),\n",
    "                         alb.RandomGamma(p=0.2), \n",
    "                         alb.RGBShift(p=0.2), \n",
    "                         alb.VerticalFlip(p=0.5)], \n",
    "                        keypoint_params=alb.KeypointParams(format='xy', label_fields=['class_labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5a3830",
   "metadata": {},
   "outputs": [],
   "source": [
    "for partition in ['train', 'test', 'val']: \n",
    "    for image in os.listdir(os.path.join('data', partition, 'images')):\n",
    "        img = cv2.imread(os.path.join('data', partition, 'images', image))\n",
    "\n",
    "        classes = [0,0]\n",
    "        coords = [0,0,0.00001,0.00001]\n",
    "        label_path = os.path.join('data', partition, 'labels', f'{image.split(\".\")[0]}.json')\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                label = json.load(f)\n",
    "    \n",
    "            if label['shapes'][0]['label']=='LeftEye': \n",
    "                classes[0] = 1\n",
    "                coords[0] = np.squeeze(label['shapes'][0]['points'])[0]\n",
    "                coords[1] = np.squeeze(label['shapes'][0]['points'])[1]\n",
    "\n",
    "            if label['shapes'][0]['label']=='RightEye':\n",
    "                classes[1] = 1\n",
    "                coords[2] = np.squeeze(label['shapes'][0]['points'])[0]\n",
    "                coords[3] = np.squeeze(label['shapes'][0]['points'])[1]\n",
    "\n",
    "            if len(label['shapes']) > 1:     \n",
    "                if label['shapes'][1]['label'] =='LeftEye': \n",
    "                    classes[0] = 1 \n",
    "                    coords[0] = np.squeeze(label['shapes'][1]['points'])[0]\n",
    "                    coords[1] = np.squeeze(label['shapes'][1]['points'])[1]\n",
    "\n",
    "                if label['shapes'][1]['label'] =='RightEye': \n",
    "                    classes[1] = 1\n",
    "                    coords[2] = np.squeeze(label['shapes'][1]['points'])[0]\n",
    "                    coords[3] = np.squeeze(label['shapes'][1]['points'])[1]\n",
    "            \n",
    "            np.divide(coords, [640,480,640,480])\n",
    "                \n",
    "        try: \n",
    "            for x in range(120):\n",
    "                keypoints = [(coords[:2]), (coords[2:])]\n",
    "                augmented = augmentor(image=img, keypoints=keypoints, class_labels=['LeftEye','RightEye'])\n",
    "                cv2.imwrite(os.path.join('aug_data', partition, 'images', f'{image.split(\".\")[0]}.{x}.jpg'), augmented['image'])\n",
    "\n",
    "                annotation = {}\n",
    "                annotation['image'] = image\n",
    "                annotation['class'] = [0,0]\n",
    "                annotation['keypoints'] = [0,0,0,0]\n",
    "\n",
    "                if os.path.exists(label_path):\n",
    "                    if len(augmented['keypoints']) > 0: \n",
    "                        for idx, cl in enumerate(augmented['class_labels']):\n",
    "                            if cl == 'LeftEye': \n",
    "                                annotation['class'][0] = 1 \n",
    "                                annotation['keypoints'][0] = augmented['keypoints'][idx][0]\n",
    "                                annotation['keypoints'][1] = augmented['keypoints'][idx][1]\n",
    "                            if cl == 'RightEye': \n",
    "                                annotation['class'][1] = 1 \n",
    "                                annotation['keypoints'][2] = augmented['keypoints'][idx][0]\n",
    "                                annotation['keypoints'][3] = augmented['keypoints'][idx][1]\n",
    "                                \n",
    "                annotation['keypoints'] = list(np.divide(annotation['keypoints'], [450,450,450,450]))\n",
    "\n",
    "\n",
    "                with open(os.path.join('aug_data', partition, 'labels', f'{image.split(\".\")[0]}.{x}.json'), 'w') as f:\n",
    "                    json.dump(annotation, f)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577c0cc5",
   "metadata": {},
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b753cb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b945d034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc3b4f8",
   "metadata": {},
   "source": [
    "### Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5db34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(x): \n",
    "    byte_img = tf.io.read_file(x)\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30e71e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = tf.data.Dataset.list_files('aug_data\\\\train\\\\images\\\\*.jpg', shuffle=False)\n",
    "train_images = train_images.map(load_image)\n",
    "train_images = train_images.map(lambda x: tf.image.resize(x, (250,250)))\n",
    "train_images = train_images.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b7dc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = tf.data.Dataset.list_files('aug_data\\\\test\\\\images\\\\*.jpg', shuffle=False)\n",
    "test_images = test_images.map(load_image)\n",
    "test_images = test_images.map(lambda x: tf.image.resize(x, (250,250)))\n",
    "test_images = test_images.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8791920",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images = tf.data.Dataset.list_files('aug_data\\\\val\\\\images\\\\*.jpg', shuffle=False)\n",
    "val_images = val_images.map(load_image)\n",
    "val_images = val_images.map(lambda x: tf.image.resize(x, (250,250)))\n",
    "val_images = val_images.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b12300c",
   "metadata": {},
   "source": [
    "### Load Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba56f8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(label_path):\n",
    "    with open(label_path.numpy(), 'r', encoding = \"utf-8\") as f:\n",
    "        label = json.load(f)\n",
    "    return [label['keypoints']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523a229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = tf.data.Dataset.list_files('aug_data\\\\train\\\\labels\\\\*.json', shuffle=False)\n",
    "train_labels = train_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.float16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cace22a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = tf.data.Dataset.list_files('aug_data\\\\test\\\\labels\\\\*.json', shuffle=False)\n",
    "test_labels = test_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.float16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e783f4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = tf.data.Dataset.list_files('aug_data\\\\val\\\\labels\\\\*.json', shuffle=False)\n",
    "val_labels = val_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.float16]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1f5c76",
   "metadata": {},
   "source": [
    "### Combining Labels and Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95177fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.data.Dataset.zip((train_images, train_labels))\n",
    "train = train.shuffle(5000)\n",
    "train = train.batch(16)\n",
    "train = train.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb51a73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.data.Dataset.zip((test_images, test_labels))\n",
    "test = test.shuffle(1300)\n",
    "test = test.batch(16)\n",
    "test = test.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffd0f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = tf.data.Dataset.zip((val_images, val_labels))\n",
    "val = val.shuffle(1000)\n",
    "val = val.batch(16)\n",
    "val = val.prefetch(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4194fcbd",
   "metadata": {},
   "source": [
    "### Viewing Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85ac639",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_samples = train.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fa01dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = data_samples.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26634ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx in range(4): \n",
    "    sample_image = res[0][idx]\n",
    "    sample_coords = res[1][0][idx]\n",
    "    \n",
    "    cv2.circle(sample_image, tuple(np.multiply(sample_coords[:2], [250,250]).astype(int)), 2, (255,0,0), -1)\n",
    "    cv2.circle(sample_image, tuple(np.multiply(sample_coords[2:], [250,250]).astype(int)), 2, (0,255,0), -1)\n",
    "    \n",
    "    ax[idx].imshow(sample_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f59ecc",
   "metadata": {},
   "source": [
    "# Building Model\n",
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cc0c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, Reshape, Dropout\n",
    "from tensorflow.keras.applications import ResNet152V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a99405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO BE MODIFIED\n",
    "model = Sequential([\n",
    "    Input(shape=(250,250,3)), \n",
    "    ResNet152V2(include_top=False, input_shape=(250,250,3)),\n",
    "    Conv2D(512, 3, padding='same', activation='relu'),\n",
    "    Conv2D(512, 3, padding='same', activation='relu'),\n",
    "    Conv2D(256, 3, 2, padding='same', activation='relu'),\n",
    "    Conv2D(256, 2, 2, activation='relu'),\n",
    "    Dropout(0.05),\n",
    "    Conv2D(4, 2, 2),\n",
    "    Reshape((4,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18608379",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509d005d",
   "metadata": {},
   "source": [
    "### Losses and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68173cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, decay=0.0007)\n",
    "loss = tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0302eb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e47ac5e",
   "metadata": {},
   "source": [
    "### Sense Check Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a4eb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a2d8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f39d34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f22f59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d81f38",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d0c58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for 100 epochs\n",
    "hist = model.fit(train, epochs=1, validation_data=val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1730d693",
   "metadata": {},
   "source": [
    "### Review Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400d7f2c",
   "metadata": {},
   "source": [
    "#### Loss Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4a8aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c730be79",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='val loss')\n",
    "plt.suptitle('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
